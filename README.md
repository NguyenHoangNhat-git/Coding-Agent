# ğŸš§ **Work in Progress** â€“ This project is under development

# ğŸ§  Simple Local AI Coding Assistant

An offline AI coding assistant that runs **locally** and integrates directly into VSCode.  
It uses a FastAPI backend with **LangGraph + Ollama** (Qwen2.5 7B by default) and a custom VSCode extension to provide code explanations, refactoring suggestions, and tool-augmented developer help â€” all **without sending code to the cloud**.

---

## âœ¨ Features

- âš¡ **Runs locally** â€” keep your code private.
- ğŸ“ **Code selection processing** â€” highlight code (optional) and ask the AI.
- ğŸ”„ **Streaming responses** with LangGraph.
- ğŸ§  **Memory** â€” per-session history stored in MongoDB.
- ğŸ›  **Tool support** â€” the agent can call functions (list files, run commands, etc.).
- ğŸ–¥ **VSCode integration** via a custom extension.
- ğŸ§© Easily switch models (Qwen, CodeLlama, etc.).

---

## ğŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ backend/                     # FastAPI + LangGraph server
â”‚   â”œâ”€â”€ main.py                  # API endpoints
â”‚   â”œâ”€â”€ agent_processor.py       # LangGraph agent (LLM + tools + memory)
â”‚   â”œâ”€â”€ tools/                   # Custom tool implementations
â”‚   â”œâ”€â”€ db.py                    # MongoDB helper for memory
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ extension/                   # VSCode extension
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ extension.ts         # Main extension activation
â”‚   â”‚   â”œâ”€â”€ apiClient.ts         # Connects to backend API
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Clone the repo

```bash
git clone https://github.com/NguyenHoangNhat-git/Coding-Agent.git
cd Coding-Agent
```

### Setup dependencies

```bash
python -m venv .venv
source .venv/bin/activate    # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### Pull the models from ollama

```bash
ollama pull mistral:7b
```

#### Run MongoDB

```bash
sudo systemctl start mongod
```

#### Run the FastAPI server

```bash
cd backend
uvicorn main:app --reload --port 8000
```

API is available at `http://localhost:8000`.

---

### Setup the VSCode Extension

```bash
cd ../extension
npm install
```

#### Run in Development Mode

1. Open the `extension` folder in VSCode.
2. Press **F5** â€” this launches a new **Extension Development Host** window.
3. Agent commands:
- In that new window, open any file, select code, press **Ctrl+Shift+P**, run `Simple Code Agent: Ask Agent`, and edit your prompt.
- Or when your coding, press Ctrl + Space to use AutoComplete
---

## ğŸ§  Memory

- Each VSCode session has a unique ID and its own history.
- Conversation history is stored in MongoDB.
- Memory resets if you restart the backend or use **Reset Session** from the extension.

---

## âš™ï¸ Configuration

- Change **default model** in `backend/agent_processor.py` (`CHAT_MODEL_NAME=..`).
- Add or modify **tools** in `backend/tools/`.
- Adjust **default system prompt** in `backend/agent_processor.py`.

---

## ğŸ›  Requirements

- Python 3.9+
- Node.js 18+
- Ollama
- MongoDB
- VSCode
