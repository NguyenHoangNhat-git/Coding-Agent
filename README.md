# ğŸ§  Simple Local AI Coding Assistant

An offline AI coding assistant that runs **locally** and integrates directly into VSCode.  
It uses a FastAPI backend with a local LLM (e.g., Qwen2.5 7B by default) and a custom VSCode extension to provide code explanations, refactoring suggestions, and other developer tools **without sending code to the cloud**.

---

## âœ¨ Features

- âš¡ **Runs locally** â€” keep your code private.
- ğŸ“ **Code selection processing** â€” highlight code and ask the AI anything.
- ğŸ”„ **Streaming responses** for real-time feedback.
- ğŸ§  **Short-term memory** â€” remembers previous interactions in a session.
- ğŸ–¥ **VSCode integration** via a custom extension.
- ğŸ§© Easily switch to different LLMs (CodeLlama, Qwen, etc.).

---

## ğŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ backend/                 # FastAPI server
â”‚   â”œâ”€â”€ main.py               # API endpoints for code processing
â”‚   â”œâ”€â”€ .env.example          # Example environment variables
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ extension/                # VSCode extension
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ extension.ts      # Main extension activation code
â”‚   â”‚   â”œâ”€â”€ apiClient.ts      # Connects to backend API
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the repo

```bash
git clone https://github.com/NguyenHoangNhat-git/Coding-Agent.git
cd Coding Agent
```

---

```bash
python -m venv .venv
source .venv/bin/activate    # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2ï¸âƒ£ Setup the Backend

#### Run the backend

```bash
cd backend
uvicorn main:app --reload --port 8000
```

Your API will be available at `http://localhost:8000`.

---

### 3ï¸âƒ£ Setup the VSCode Extension

```bash
cd ../extension
npm install
# may have to run 'npm run watch' or 'npm run compile' if you modify sth
```

#### Run in Development Mode

1. Open the `extension` folder in VSCode.
2. Press **F5** â€” this launches a new **Extension Development Host** window.
3. In that new window, open any code file, select some code, press **Ctrl+Shift+P**, run `Simple Code Agent: Explain Code` -> Edit the prompt.

---

## ğŸ§  Memory

- This project now supports short-term memory for conversations.

- Each session (session_id="default" by default) maintains its own history of user prompts and AI responses (check `backend/memory.py` to change default limits).

- You can extend this later to support multiple conversations or users by changing the session_id passed from the extension.

- Memory currently lives in RAM and resets when the backend restarts.

---

## âš™ï¸ Configuration

You can change:

- **Backend model** (e.g., CodeLlama, Qwen) in `backend/main.py`.
- **Default prompt** in `extension/src/extension.ts`.

---

## ğŸ›  Requirements

- Python 3.9+
- Node.js 18+
- Ollama
- VSCode
