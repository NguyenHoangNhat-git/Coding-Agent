# üöß **Work in Progress** ‚Äì This project is under development

# üß† Simple Local AI Coding Assistant

An offline AI coding assistant that runs **locally** and integrates directly into VSCode.  
It uses a FastAPI backend with **LangGraph + Ollama** and a custom VSCode extension to provide code explanations, refactoring suggestions, and tool-augmented developer help ‚Äî all **without sending code to the cloud**.

---

## ‚ú® Features

- ‚ö° **Runs locally** ‚Äî keep your code private.
- üìù **Code selection processing** ‚Äî highlight code (optional) and ask the AI.
- üîÑ **Streaming responses** with LangGraph.
- üß† **Memory** ‚Äî session history stored in MongoDB.
- üõ† **Tool support** ‚Äî the agent can call functions (list files, run commands, etc.).
- üñ• **VSCode integration** via a custom extension.
- üß© Easily switch models (Qwen, CodeLlama, etc.).

---

## üìÇ Project Structure

```
project-root/
‚îÇ
‚îú‚îÄ‚îÄ backend/                     # FastAPI + LangGraph server
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ agent_processor.py       # LangGraph agent (LLM + tools + memory)
‚îÇ   ‚îú‚îÄ‚îÄ tools/                   # Custom tool implementations
‚îÇ   ‚îú‚îÄ‚îÄ db.py                    # MongoDB helper for memory
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ extension/                   # VSCode extension
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extension.ts         # Main extension activation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ apiClient.ts         # Connects to backend API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ tsconfig.json
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Getting Started

### Clone the repo

```bash
git clone https://github.com/NguyenHoangNhat-git/Coding-Agent.git
cd Coding-Agent
```

### Setup dependencies

```bash
python -m venv .venv
source .venv/bin/activate    # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### Pull the models from ollama

Pull mistral(for agent) and qwen(for autocomplete)

```bash
ollama pull mistral:7b
ollama pull qwen2.5-coder:1.5b
```

#### Run MongoDB

```bash
sudo systemctl start mongod
```

#### Run the FastAPI server

```bash
cd backend
uvicorn main:app --reload --port 8000
```

API is available at `http://localhost:8000`.

---

### Setup the VSCode Extension

```bash
cd ../extension
npm install
```

#### Run

1. Open the `extension` folder in VSCode.
2. Press **F5** -> launch a new **Extension Development Host** window.
3. Press **Ctrl+Shift+P** to search for commands
4. Agent commands:

- Select a piece of code and run `Simple Code Agent: Ask Agent` to ask for explanation or just general questions.
- Run `Simple code agent: Toggle settings` to to turn on/off chat and/or autocomplete model.
- Run `Simple code agent: Reset session` to clear the memory

---

## ‚öôÔ∏è Configuration

- Change **default models** in `backend/models_manager.py`.
- Add or modify **tools** in `backend/tools/`.
- Adjust **default system prompt** in `backend/agent_processor.py`.

---

## üõ† Requirements

- Python 3.9+
- Node.js 18+
- Ollama
- MongoDB
- VSCode
